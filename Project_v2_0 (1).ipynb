{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Project**"
      ],
      "metadata": {
        "id": "C6eqCdbJU8Q6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading and label numbers of dataset:"
      ],
      "metadata": {
        "id": "C__8i_hN85xR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oIL9UdoqyveA"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"/content/train.csv\")\n",
        "\n",
        "print(\"Shape:\", df.shape)\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_cols = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
        "\n",
        "label_counts = df[label_cols].sum().sort_values()\n",
        "\n",
        "print(\"Label distribution:\\n\")\n",
        "print(label_counts)\n"
      ],
      "metadata": {
        "id": "ezjnTJKZ7Scn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split:"
      ],
      "metadata": {
        "id": "O6j6B9nr83oy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "label_cols = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
        "\n",
        "\n",
        "df[\"has_toxicity\"] = (df[label_cols].sum(axis=1) > 0).astype(int)\n",
        "\n",
        "train_df, val_df = train_test_split(\n",
        "    df,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=df[\"has_toxicity\"]\n",
        ")\n",
        "\n",
        "\n",
        "train_df = train_df.drop(columns=[\"has_toxicity\"])\n",
        "val_df = val_df.drop(columns=[\"has_toxicity\"])\n",
        "\n",
        "print(\"Train shape:\", train_df.shape)\n",
        "print(\"Validation shape:\", val_df.shape)\n"
      ],
      "metadata": {
        "id": "28v3Ohhr7l82"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cleaning Data:"
      ],
      "metadata": {
        "id": "4WUjnJJY80sc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def clean_text(text):\n",
        "    text = str(text)\n",
        "    text = re.sub(r\"http\\S+|www\\S+|https\\S+\", \"\", text)\n",
        "    text = re.sub(r\"@\\w+\", \"\", text)\n",
        "    text = re.sub(r\"(.)\\1{3,}\", r\"\\1\\1\", text)\n",
        "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
        "    return text\n",
        "\n",
        "train_df[\"comment_text\"] = train_df[\"comment_text\"].apply(clean_text)\n",
        "val_df[\"comment_text\"] = val_df[\"comment_text\"].apply(clean_text)\n"
      ],
      "metadata": {
        "id": "IDQYofcB8ySK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset Switch:"
      ],
      "metadata": {
        "id": "skKq2OPrJAog"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TRAINING MODE SWITCH\n",
        "\n",
        "\n",
        "TRAIN_MODE = \"original\"   # change to \"augmented\" when needed\n",
        "\n",
        "if TRAIN_MODE == \"original\":\n",
        "    training_df = train_df\n",
        "    print(\"Training on ORIGINAL data only\")\n",
        "\n",
        "elif TRAIN_MODE == \"augmented\":\n",
        "    training_df = pd.concat([train_df, aug_df], ignore_index=True)\n",
        "    training_df = training_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "    print(\"Training on ORIGINAL + AUGMENTED data\")\n",
        "\n",
        "else:\n",
        "    raise ValueError(\"TRAIN_MODE must be 'original' or 'augmented'\")\n",
        "\n",
        "print(\"Training samples:\", len(training_df))\n",
        "print(\"Validation samples:\", len(val_df))\n"
      ],
      "metadata": {
        "id": "pDOggKUmJEui"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "BERT Tokenization:"
      ],
      "metadata": {
        "id": "ws5Eigwf-hZz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import BertTokenizer\n"
      ],
      "metadata": {
        "id": "VtbO5xs7BnLz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n"
      ],
      "metadata": {
        "id": "GRXbOi2P9HH0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ToxicDataset(Dataset):\n",
        "    def __init__(self, dataframe, tokenizer, max_len=128):\n",
        "        self.texts = dataframe[\"comment_text\"].values\n",
        "        self.labels = dataframe[label_cols].values\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = str(self.texts[idx])\n",
        "        labels = torch.tensor(self.labels[idx], dtype=torch.float)\n",
        "\n",
        "        encoding = self.tokenizer.encode_plus(\n",
        "            text,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            padding=\"max_length\",\n",
        "            truncation=True,\n",
        "            return_attention_mask=True,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            \"input_ids\": encoding[\"input_ids\"].squeeze(0),\n",
        "            \"attention_mask\": encoding[\"attention_mask\"].squeeze(0),\n",
        "            \"labels\": labels\n",
        "        }\n"
      ],
      "metadata": {
        "id": "MrAwWjHz-k9T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = ToxicDataset(training_df, tokenizer)\n",
        "val_dataset = ToxicDataset(val_df, tokenizer)\n"
      ],
      "metadata": {
        "id": "-fLcW4UV-p1A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 16\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, pin_memory=True)\n",
        "val_loader   = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "print(\"Train samples:\", len(train_loader.dataset))\n",
        "print(\"Val samples:\", len(val_loader.dataset))\n"
      ],
      "metadata": {
        "id": "BqRIW37B-rp6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sanity Check:"
      ],
      "metadata": {
        "id": "1Fkr6LX9-vCk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch = next(iter(train_loader))\n",
        "\n",
        "print(\"Input IDs shape:\", batch[\"input_ids\"].shape)\n",
        "print(\"Attention mask shape:\", batch[\"attention_mask\"].shape)\n",
        "print(\"Labels shape:\", batch[\"labels\"].shape)\n"
      ],
      "metadata": {
        "id": "WyBD9rsr-whq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "BERT Model (no augmentaion)"
      ],
      "metadata": {
        "id": "VEAotcW__Ruk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "from transformers import BertModel\n",
        "\n",
        "class BertToxicClassifier(nn.Module):\n",
        "    def __init__(self, n_labels):\n",
        "        super(BertToxicClassifier, self).__init__()\n",
        "        self.bert = BertModel.from_pretrained(\"bert-base-uncased\")\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "        self.classifier = nn.Linear(self.bert.config.hidden_size, n_labels)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        pooled_output = outputs.pooler_output  # [CLS] token representation\n",
        "        pooled_output = self.dropout(pooled_output)\n",
        "        logits = self.classifier(pooled_output)\n",
        "        return logits\n"
      ],
      "metadata": {
        "id": "j1uUFi2V_VGc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = BertToxicClassifier(n_labels=len(label_cols))\n",
        "model = model.to(device)\n",
        "\n",
        "print(\"Using device:\", device)\n"
      ],
      "metadata": {
        "id": "4-hRKPHh_Ymk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---------\n",
        "\n"
      ],
      "metadata": {
        "id": "QYLFh7UJNPih"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Augmentation**"
      ],
      "metadata": {
        "id": "IqnnQm8sRwk-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Minority class sample extraction:"
      ],
      "metadata": {
        "id": "86vV6xTVR0Cb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "label_counts = train_df[label_cols].sum().sort_values()\n",
        "print(label_counts)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yRmCh6bnSFLl",
        "outputId": "a00d052e-c501-4937-a567-1366448f955e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "threat             380\n",
            "identity_hate     1146\n",
            "severe_toxic      1290\n",
            "insult            6301\n",
            "obscene           6787\n",
            "toxic            12248\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "minority_labels = [\"threat\", \"identity_hate\"]\n",
        "minority_df = train_df[train_df[minority_labels].any(axis=1)].copy()\n",
        "\n",
        "print(\"Minority samples count:\", len(minority_df))\n",
        "minority_df.head()\n"
      ],
      "metadata": {
        "id": "U-pbQI61SIom"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(minority_df)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "ote08z_gScWN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model for Paraphrasing Implementation:"
      ],
      "metadata": {
        "id": "I411kAZOU1t_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai tqdm\n",
        "\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from openai import OpenAI\n",
        "import time\n"
      ],
      "metadata": {
        "id": "veBsHrUnU0dl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "client = OpenAI(api_key=\"_Your_API_Key_Here\")\n"
      ],
      "metadata": {
        "id": "wnzCag96VCnX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Paraphrasing Function:"
      ],
      "metadata": {
        "id": "nPONkSoAWJOk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_paraphrases(text, n=2):\n",
        "    prompt = f\"\"\"\n",
        "Paraphrase the following toxic online comment.\n",
        "Keep the meaning and level of offensiveness the same.\n",
        "Return {n} different paraphrased versions as a numbered list.\n",
        "\n",
        "Comment: \"{text}\"\n",
        "\"\"\"\n",
        "\n",
        "    try:\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"gpt-4o-mini\",\n",
        "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "            service_tier=\"priority\"\n",
        "        )\n",
        "\n",
        "        output = response.choices[0].message.content\n",
        "\n",
        "        # Splits numbered list into separate paraphrases\n",
        "        paras = []\n",
        "        for line in output.split(\"\\n\"):\n",
        "            line = line.strip()\n",
        "            if line and line[0].isdigit():\n",
        "                paras.append(line.split(\".\", 1)[1].strip())\n",
        "\n",
        "        return paras[:n]\n",
        "\n",
        "    except Exception as e:\n",
        "        print(\"Error:\", e)\n",
        "        time.sleep(2)\n",
        "        return []\n"
      ],
      "metadata": {
        "id": "-Wst9TUeWMFG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "API Calls:"
      ],
      "metadata": {
        "id": "GI1EupXJWgPU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "augmented_rows = []\n",
        "\n",
        "for _, row in tqdm(minority_df.iterrows(), total=len(minority_df)):\n",
        "    text = row[\"comment_text\"]\n",
        "    labels = row[label_cols].values\n",
        "\n",
        "    paraphrases = generate_paraphrases(text, n=2)\n",
        "\n",
        "    for para in paraphrases:\n",
        "        new_row = row.copy()\n",
        "        new_row[\"comment_text\"] = para\n",
        "        augmented_rows.append(new_row)\n",
        "\n",
        "augmented_df = pd.DataFrame(augmented_rows)\n",
        "print(\"Generated paraphrases:\", len(augmented_df))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ONROGhh0WfEi",
        "outputId": "1502c371-988e-4fe9-f7c2-2eabd804a703"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1442/1442 [27:50<00:00,  1.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated paraphrases: 2271\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Merging with Training Data:"
      ],
      "metadata": {
        "id": "D3_BWTQDWky0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "aug_df = pd.DataFrame(augmented_rows)\n",
        "aug_df.to_csv(\"augmented_train.csv\", index=False)\n",
        "\n",
        "print(\"Saved!\", len(aug_df), \"augmented samples\")\n"
      ],
      "metadata": {
        "id": "lGTw4K5yg8nT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "aug_df = pd.read_csv(\"/content/augmented_train.csv\")\n",
        "\n",
        "# Combine with original training data\n",
        "full_train_df = pd.concat([train_df, aug_df], ignore_index=True)\n",
        "\n",
        "print(\"Original train size:\", len(train_df))\n",
        "print(\"Augmented train size:\", len(full_train_df))\n"
      ],
      "metadata": {
        "id": "Kdmk-en3iHs_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Class-Weighted Version:\n",
        "\n",
        "\n",
        "P.S. Run this again after augmentation and merging"
      ],
      "metadata": {
        "id": "QNEp4vw8za8J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "label_counts = training_df[label_names].sum().values\n",
        "total_samples = len(train_df)\n",
        "\n",
        "pos_weights = (total_samples - label_counts) / label_counts\n",
        "\n",
        "# Prevent exploding weights\n",
        "pos_weights = np.clip(pos_weights, 1, 20)\n",
        "\n",
        "pos_weights = torch.tensor(pos_weights, dtype=torch.float).to(device)\n",
        "\n",
        "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weights)\n"
      ],
      "metadata": {
        "id": "keI_u2d5zaQ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training & Validation Function:"
      ],
      "metadata": {
        "id": "R36EFSuTDW8y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import f1_score, classification_report\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "def train_model(model, train_loader, val_loader, optimizer, criterion, device, epochs=3):\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        print(f\"\\nEpoch {epoch+1}/{epochs}\")\n",
        "\n",
        "        # Training\n",
        "        model.train()\n",
        "        total_train_loss = 0\n",
        "\n",
        "        train_bar = tqdm(train_loader, desc=\"Training\", leave=False)\n",
        "\n",
        "        for batch in train_bar:\n",
        "            input_ids = batch[\"input_ids\"].to(device)\n",
        "            attention_mask = batch[\"attention_mask\"].to(device)\n",
        "            labels = batch[\"labels\"].to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(input_ids, attention_mask=attention_mask)\n",
        "            loss = criterion(outputs.logits, labels)\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "            optimizer.step()\n",
        "\n",
        "            total_train_loss += loss.item()\n",
        "            train_bar.set_postfix(loss=loss.item())\n",
        "\n",
        "        avg_train_loss = total_train_loss / len(train_loader)\n",
        "        print(\"Train Loss:\", round(avg_train_loss, 4))\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        total_val_loss = 0\n",
        "        all_preds, all_labels = [], []\n",
        "\n",
        "        val_bar = tqdm(val_loader, desc=\"Validating\", leave=False)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch in val_bar:\n",
        "                input_ids = batch[\"input_ids\"].to(device)\n",
        "                attention_mask = batch[\"attention_mask\"].to(device)\n",
        "                labels = batch[\"labels\"].to(device)\n",
        "\n",
        "                outputs = model(input_ids, attention_mask=attention_mask)\n",
        "                loss = criterion(outputs.logits, labels)\n",
        "                total_val_loss += loss.item()\n",
        "\n",
        "                preds = torch.sigmoid(outputs.logits).cpu().numpy()\n",
        "                all_preds.append(preds)\n",
        "                all_labels.append(labels.cpu().numpy())\n",
        "\n",
        "                val_bar.set_postfix(loss=loss.item())\n",
        "\n",
        "        avg_val_loss = total_val_loss / len(val_loader)\n",
        "\n",
        "        all_preds = (np.vstack(all_preds) > 0.5).astype(int)\n",
        "        all_labels = np.vstack(all_labels)\n",
        "\n",
        "        macro_f1 = f1_score(all_labels, all_preds, average=\"macro\")\n",
        "        micro_f1 = f1_score(all_labels, all_preds, average=\"micro\")\n",
        "\n",
        "        print(\"Val Loss:\", round(avg_val_loss, 4))\n",
        "        print(\"Val Macro F1:\", round(macro_f1, 4))\n",
        "        print(\"Val Micro F1:\", round(micro_f1, 4))\n",
        "\n",
        "        label_names = ['toxic','severe_toxic','obscene','threat','insult','identity_hate']\n",
        "        print(\"\\nPer-class F1:\")\n",
        "        print(classification_report(all_labels, all_preds, target_names=label_names, zero_division=0))"
      ],
      "metadata": {
        "id": "UA31ahDUDTaC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run Training:  "
      ],
      "metadata": {
        "id": "OCN6qDvvifh3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def move_to_device(batch, device):\n",
        "    return {\n",
        "        \"input_ids\": batch[\"input_ids\"].to(device),\n",
        "        \"attention_mask\": batch[\"attention_mask\"].to(device),\n",
        "        \"labels\": batch[\"labels\"].to(device)\n",
        "    }\n"
      ],
      "metadata": {
        "id": "vsq11znPDOo9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class ToxicDataset(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_len=128):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        encoding = self.tokenizer(\n",
        "            str(self.texts[idx]),\n",
        "            truncation=True,\n",
        "            padding=\"max_length\",\n",
        "            max_length=self.max_len,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            \"input_ids\": encoding[\"input_ids\"].squeeze(0),\n",
        "            \"attention_mask\": encoding[\"attention_mask\"].squeeze(0),\n",
        "            \"labels\": torch.tensor(self.labels[idx], dtype=torch.float)\n",
        "        }\n",
        "\n",
        "label_cols = ['toxic','severe_toxic','obscene','threat','insult','identity_hate']\n",
        "\n",
        "train_dataset = ToxicDataset(\n",
        "    full_train_df[\"comment_text\"].values,\n",
        "    full_train_df[label_cols].values,\n",
        "    tokenizer\n",
        ")\n",
        "\n",
        "val_dataset = ToxicDataset(\n",
        "    val_df[\"comment_text\"].values,\n",
        "    val_df[label_cols].values,\n",
        "    tokenizer\n",
        ")\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=16)\n"
      ],
      "metadata": {
        "id": "RsEWiHfMimF4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    \"distilbert-base-uncased\",\n",
        "    num_labels=6,\n",
        "    problem_type=\"multi_label_classification\"\n",
        ")\n",
        "\n",
        "model.to(device)\n"
      ],
      "metadata": {
        "id": "awwupY6AitBN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "from torch.optim import AdamW\n",
        "\n",
        "#criterion = nn.BCEWithLogitsLoss()\n",
        "criterion = nn.BCEWithLogitsLoss(pos_weight=weights.to(device))\n",
        "optimizer = AdamW(model.parameters(), lr=1e-5)\n"
      ],
      "metadata": {
        "id": "8R6-oXdiiyGx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_model(model, train_loader, val_loader, optimizer, criterion, device, epochs=2)\n"
      ],
      "metadata": {
        "id": "H_Cv-3E0jbp3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Reinitializing:"
      ],
      "metadata": {
        "id": "fImANdJl2sBi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=6, problem_type=\"multi_label_classification\").to(device)\n"
      ],
      "metadata": {
        "id": "gUcGLWli2z_O"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}